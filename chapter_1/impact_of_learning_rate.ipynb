{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-07T10:04:44.099917Z",
     "start_time": "2025-10-07T10:04:44.090080Z"
    }
   },
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# specify input and output datasets\n",
    "x = [[1], [2], [3], [4]]\n",
    "y = [[3], [4], [9], [12]]"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T10:07:37.124523Z",
     "start_time": "2025-10-07T10:07:37.097404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define feedforward function, no hidden layer, architecture: y=w*x+b\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "def feed_forward(inputs, outputs, weights):\n",
    "    pred_out = np.dot(inputs, weights[0]) + weights[1]\n",
    "    mean_squared_error = np.mean(np.square(pred_out - outputs))\n",
    "    return mean_squared_error"
   ],
   "id": "a066a0ac71923091",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T10:08:17.361116Z",
     "start_time": "2025-10-07T10:08:17.345867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define update_weights function\n",
    "# define the update weights section\n",
    "def update_weights(inputs, outputs, weights, lr):\n",
    "    \"\"\"performs gradient descent process to update weights\n",
    "    Inputs:\n",
    "     inputs: input variable to the network\n",
    "     outputs: output variable to the network\n",
    "     weights: weights variable to the network\n",
    "     lr: learning rate\n",
    "    weights are randomly initialized at the start of training the model\n",
    "    \"\"\"\n",
    "    # use deepcopy: this ensures that we work with multiple copies of weights without disturbing the original weigth values\n",
    "    original_weights = deepcopy(weights)\n",
    "    temp_weights = deepcopy(weights)\n",
    "    updated_weights = deepcopy(weights)\n",
    "\n",
    "    # calculate the loss value with the original set of weights\n",
    "    original_loss = feed_forward(inputs, outputs, original_weights)\n",
    "\n",
    "    # loop thru all the layers of the network\n",
    "    for i, layer in enumerate(original_weights):\n",
    "        # loop thru all the individual parameters\n",
    "        for index, weight in np.ndenumerate(layer):\n",
    "            # select a weight and increase it by a small value\n",
    "            temp_weights = deepcopy(weights)\n",
    "            temp_weights[i][index] += 0.0001\n",
    "            _loss_plus = feed_forward(inputs, outputs, temp_weights)\n",
    "\n",
    "            # calculate the gradient descent due to the weight change\n",
    "            grad = (_loss_plus - original_loss) / 0.0001\n",
    "\n",
    "            # update the parameter present in the  corresponding layer and index of updated_weights\n",
    "            updated_weights[i][index] -= grad*lr\n",
    "    return updated_weights"
   ],
   "id": "9ff412167fb9bb4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T10:09:35.658368Z",
     "start_time": "2025-10-07T10:09:35.630143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# initialize weight and bias values to a random variable\n",
    "W = [np.array([[0]], dtype=np.float32),\n",
    "     np.array([[0]], dtype=np.float32)]"
   ],
   "id": "dd6df32b5f88f63d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T10:12:56.406594Z",
     "start_time": "2025-10-07T10:12:56.030711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# leverage the update_weights function and check how the weight value varies over increasing epochs\n",
    "weight_value = []\n",
    "for epx in range(1000):\n",
    "    W = update_weights(x, y, W, 0.01)\n",
    "    weight_value.append(W[0][0][0])"
   ],
   "id": "65f8d308356a8914",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-07T10:15:36.239885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot the value of weight parameter at the end of each epoch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "epochs = range(1, 1001)\n",
    "plt.plot(epochs, weight_value)\n",
    "plt.title(\"weight value over increasing epochs when the lr is 0.01\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"weight value\")"
   ],
   "id": "17eb378616d61816",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'weight value')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In general, it is better to have a low learning rate. This way, the\n",
    " model is able to learn slowly but will adjust the weights toward\n",
    " an optimal value. Typical learning rate parameter values range\n",
    " between 0.0001 and 0.01."
   ],
   "id": "faf73e3a482f58d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d3feb623d7a31372"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
