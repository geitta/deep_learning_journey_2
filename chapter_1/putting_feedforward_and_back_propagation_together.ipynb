{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "the simple network built will have two input layers, three hidden layers and one output layer. all layers a re well connected.",
   "id": "903b1bfec417c2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-07T09:03:40.102899Z",
     "start_time": "2025-10-07T09:03:39.776110Z"
    }
   },
   "source": [
    "# import relevant packages and define the dataset\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "x = np.array([[1, 1]])\n",
    "y = np.array([[0]])\n",
    "x, y"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1]]), array([[0]]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:12:39.705275Z",
     "start_time": "2025-10-07T09:12:39.687833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# initialize weight and bias values randomly\n",
    "W = [\n",
    "np.array([[-0.0053, 0.3793],\n",
    "    [-0.5820, -0.5204],\n",
    "    [-0.2723, 0.1896]], dtype=np.float32).T, # 2 x 3 matrix of weights that connect the input layer to the hidden layer\n",
    "np.array([-0.0140, 0.5607, -0.0628], dtype=np.float32), # this array reps the bias values associated with each node of the hidden layer\n",
    "np.array([[ 0.1528,-0.1745,-0.1135]],dtype=np.float32).T, # this array corresponds to the 3x1 matrix of weights joining the hidden layer to the output layer\n",
    "np.array([-0.5516], dtype=np.float32) # represents the bias associated with the output layer\n",
    "]"
   ],
   "id": "653148dd39f66b24",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:14:25.020849Z",
     "start_time": "2025-10-07T09:14:24.997872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the feedforward function\n",
    "def feed_forward(inputs, outputs, weights):\n",
    "    pre_hidden = np.dot(inputs, weights[0]) + weights[1]\n",
    "    hidden = 1/(1 + np.exp(-pre_hidden))\n",
    "    pred_out = np.dot(hidden, weights[2]) + weights[3]\n",
    "    mean_squared_error = np.mean(np.square(pred_out - outputs))\n",
    "    return mean_squared_error"
   ],
   "id": "1347651e74d9e3e1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:14:54.231387Z",
     "start_time": "2025-10-07T09:14:54.210083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the update weights section\n",
    "def update_weights(inputs, outputs, weights, lr):\n",
    "    \"\"\"performs gradient descent process to update weights\n",
    "    Inputs:\n",
    "     inputs: input variable to the network\n",
    "     outputs: output variable to the network\n",
    "     weights: weights variable to the network\n",
    "     lr: learning rate\n",
    "    weights are randomly initialized at the start of training the model\n",
    "    \"\"\"\n",
    "    # use deepcopy: this ensures that we work with multiple copies of weights without disturbing the original weigth values\n",
    "    original_weights = deepcopy(weights)\n",
    "    temp_weights = deepcopy(weights)\n",
    "    updated_weights = deepcopy(weights)\n",
    "\n",
    "    # calculate the loss value with the original set of weights\n",
    "    original_loss = feed_forward(inputs, outputs, original_weights)\n",
    "\n",
    "    # loop thru all the layers of the network\n",
    "    for i, layer in enumerate(original_weights):\n",
    "        # loop thru all the individual parameters\n",
    "        for index, weight in np.ndenumerate(layer):\n",
    "            # select a weight and increase it by a small value\n",
    "            temp_weights = deepcopy(weights)\n",
    "            temp_weights[i][index] += 0.0001\n",
    "            _loss_plus = feed_forward(inputs, outputs, temp_weights)\n",
    "\n",
    "            # calculate the gradient descent due to the weight change\n",
    "            grad = (_loss_plus - original_loss) / 0.0001\n",
    "\n",
    "            # update the parameter present in the  corresponding layer and index of updated_weights\n",
    "            updated_weights[i][index] -= grad*lr\n",
    "    return updated_weights, original_loss"
   ],
   "id": "8d41d0074d5293a8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:16:05.739860Z",
     "start_time": "2025-10-07T09:16:05.458430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# update weights over 100 epochs and fetch the loss values anf the updated weight values\n",
    "losses = []\n",
    "for epoch in range(100):\n",
    "    W, loss = update_weights(x, y, W, 0.01)\n",
    "    losses.append(loss)"
   ],
   "id": "6b1ea70dec819a39",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# once we have the updated weights, make the predictions for the inputby passing the input through the network and calculate the output value\n",
    "pre_hidden = np.dot(x, W[0]) + W[1]\n",
    "hidden = 1 / (1 + np.exp(-pre_hidden))\n",
    "pred_out = np.dot(hidden, W[2]) + W[3]\n",
    "pred_out"
   ],
   "id": "c1b3b29a3e0fd6a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf9c3ab8eb7e7264"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
