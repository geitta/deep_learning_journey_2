{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "1. define the feedforward network and caldulate the mean squared error loss value",
   "id": "5a9a60ae51c55dc1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T06:47:38.589197Z",
     "start_time": "2025-10-06T06:47:38.073644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "def feed_forward(inputs, outputs, weights):\n",
    "    pre_hidden = np.dot(inputs, weights[0]) + weights[1]\n",
    "    hidden = 1/(1 + np.exp(-pre_hidden))\n",
    "    pred_out = np.dot(hidden, weights[2]) + weights[3]\n",
    "    mean_squared_error = np.mean(np.square(pred_out - outputs))\n",
    "    return mean_squared_error"
   ],
   "id": "15c4960dd00f7aa6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. increase each weight and bias value by a very small amount (0.0001) and calculate the overall squared error loss value one at a time for each of the weight and bias updates",
   "id": "1ccb3f870ad834ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T07:05:58.684137Z",
     "start_time": "2025-10-06T07:05:58.670067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_weights(inputs, outputs, weights, lr):\n",
    "    \"\"\"performs gradient descent process to update weights\n",
    "    Inputs:\n",
    "     inputs: input variable to the network\n",
    "     outputs: output variable to the network\n",
    "     weights: weights variable to the network\n",
    "     lr: learning rate\n",
    "    weights are randomly initialized at the start of training the model\n",
    "    \"\"\"\n",
    "    # use deepcopy: this ensures that we work with multiple copies of weights without disturbing the original weigth values\n",
    "    original_weights = deepcopy(weights)\n",
    "    temp_weights = deepcopy(weights)\n",
    "    updated_weights = deepcopy(weights)\n",
    "\n",
    "    # calculate the loss value with the original set of weights\n",
    "    original_loss = feed_forward(inputs, outputs, original_weights)\n",
    "\n",
    "    # loop thru all the layers of the network\n",
    "    for i, layer in enumerate(original_weights):\n",
    "        # loop thru all the individual parameters\n",
    "        for index, weight in np.ndenumerate(layer):\n",
    "            # select a weight and increase it by a small value\n",
    "            temp_weights = deepcopy(weights)\n",
    "            temp_weights[i][index] += 0.0001\n",
    "            _loss_plus = feed_forward(inputs, outputs, temp_weights)\n",
    "\n",
    "            # calculate the gradient descent due to the weight change\n",
    "            grad = (_loss_plus - original_loss) / 0.0001\n",
    "\n",
    "            # update the parameter present in the  corresponding layer and index of updated_weights\n",
    "            updated_weights[i][index] -= grad*lr\n",
    "    return updated_weights, original_loss"
   ],
   "id": "4f1ca70d009e576d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a1e3fe9c11b966dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
