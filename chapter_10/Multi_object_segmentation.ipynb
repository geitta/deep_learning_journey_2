{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PacktPublishing/Modern-Computer-Vision-with-PyTorch-2E/blob/main/Chapter10/Multi_object_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O6zkXVmBwyRi"
      },
      "outputs": [],
      "source": [
        "%pip install -qU openimages torch_snippets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5dWAJWpew-Rp"
      },
      "outputs": [],
      "source": [
        "from torch_snippets import *\n",
        "!wget -O train-annotations-object-segmentation.csv -q https://storage.googleapis.com/openimages/v5/train-annotations-object-segmentation.csv\n",
        "!wget -O classes.csv -q https://raw.githubusercontent.com/openimages/dataset/master/dict.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t3ZsaZyd9EkT"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch_snippets import *\n",
        "from builtins import print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PBI7wUaow_0w"
      },
      "outputs": [],
      "source": [
        "required_classes = 'person,dog,bird,car,elephant,football,jug,laptop,mushroom,pizza,rocket,shirt,traffic sign,watermelon,zebra'\n",
        "required_classes = [c.lower() for c in required_classes.lower().split(',')]\n",
        "\n",
        "classes = pd.read_csv('classes.csv', header=None)\n",
        "classes.columns = ['class','class_name']\n",
        "classes = classes[classes['class_name'].map(lambda x: x in required_classes)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "o_jIb7eGxDU5"
      },
      "outputs": [],
      "source": [
        "from torch_snippets import *\n",
        "df = pd.read_csv('train-annotations-object-segmentation.csv')\n",
        "df.head()\n",
        "\n",
        "data = pd.merge(df, classes, left_on='LabelName', right_on='class')\n",
        "\n",
        "subset_data = data.groupby('class_name').agg({'ImageID': lambda x: list(x)[:500]})\n",
        "subset_data = flatten(subset_data.ImageID.tolist())\n",
        "subset_data = data[data['ImageID'].map(lambda x: x in subset_data)]\n",
        "subset_masks = subset_data['MaskPath'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dkhb9-IPxTW1",
        "outputId": "490c70e5-64a3-4623-d230-78883f0ca154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▎        | 2/16 [03:43<25:27, 109.08s/it]"
          ]
        }
      ],
      "source": [
        "!mkdir -p masks\n",
        "for c in Tqdm('0123456789abcdef'):\n",
        "    !wget -q https://storage.googleapis.com/openimages/v5/train-masks/train-masks-{c}.zip\n",
        "    !unzip -q train-masks-{c}.zip -d tmp_masks\n",
        "    !rm train-masks-{c}.zip\n",
        "    tmp_masks = Glob('tmp_masks', silent=True)\n",
        "    items = [(m,fname(m)) for m in tmp_masks]\n",
        "    items = [(i,j) for (i,j) in items if j in subset_masks]\n",
        "    for i,j in items:\n",
        "        os.rename(i, f'masks/{j}')\n",
        "    !rm -rf tmp_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH6WAiisxhIW"
      },
      "outputs": [],
      "source": [
        "masks = Glob('masks')\n",
        "masks = [fname(mask) for mask in masks]\n",
        "\n",
        "subset_data = subset_data[subset_data['MaskPath'].map(lambda x: x in masks)]\n",
        "subset_imageIds = subset_data['ImageID'].tolist()\n",
        "\n",
        "from openimages.download import _download_images_by_id\n",
        "!mkdir images\n",
        "_download_images_by_id(subset_imageIds, 'train', './images/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7N15Isujxscb"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "files = Glob('images') + Glob('masks') + ['train-annotations-object-segmentation.csv', 'classes.csv']\n",
        "with zipfile.ZipFile('data.zip','w') as zipme:\n",
        "    for file in Tqdm(files):\n",
        "        zipme.write(file, compress_type=zipfile.ZIP_DEFLATED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03rupy02xssq"
      },
      "outputs": [],
      "source": [
        "!mkdir -p train/\n",
        "!mv images train/myData2020\n",
        "!mv masks train/annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBpgR64gxuQ1"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/sizhky/pycococreator.git\n",
        "%cd pycococreator\n",
        "%pip install -e .\n",
        "%cd -\n",
        "%pip install pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC-ID-NRUg-M"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "INFO = {\n",
        "    \"description\": \"MyData2020\",\n",
        "    \"url\": \"None\",\n",
        "    \"version\": \"1.0\",\n",
        "    \"year\": 2020,\n",
        "    \"contributor\": \"sizhky\",\n",
        "    \"date_created\": datetime.datetime.utcnow().isoformat(' ')\n",
        "}\n",
        "\n",
        "LICENSES = [\n",
        "    {\n",
        "        \"id\": 1,\n",
        "        \"name\": \"MIT\"\n",
        "    }\n",
        "]\n",
        "\n",
        "CATEGORIES = [{'id': id+1, 'name': name.replace('/',''), 'supercategory': 'none'} for id,(_,(name, clss_name)) in enumerate(classes.iterrows())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OLxzKH7x2SR"
      },
      "outputs": [],
      "source": [
        "from pycococreator.pycococreatortools import pycococreatortools\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "\n",
        "coco_output = {\n",
        "    \"info\": INFO,\n",
        "    \"licenses\": LICENSES,\n",
        "    \"categories\": CATEGORIES,\n",
        "    \"images\": [],\n",
        "    \"annotations\": []\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJfdU5tjx8vd"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR = \"train\"\n",
        "IMAGE_DIR, ANNOTATION_DIR = 'train/myData2020/', 'train/annotations/'\n",
        "image_files = [f for f in listdir(IMAGE_DIR) if isfile(join(IMAGE_DIR, f))]\n",
        "annotation_files = [f for f in listdir(ANNOTATION_DIR) if isfile(join(ANNOTATION_DIR, f))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AC5BdfNx_Zj"
      },
      "outputs": [],
      "source": [
        "image_id = 1\n",
        "# go through each image\n",
        "for image_filename in Tqdm(image_files):\n",
        "    image = Image.open(IMAGE_DIR + '/' + image_filename)\n",
        "    image_info = pycococreatortools.create_image_info(image_id, os.path.basename(image_filename), image.size)\n",
        "    coco_output[\"images\"].append(image_info)\n",
        "    image_id = image_id + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaK7kCT9yLy2"
      },
      "outputs": [],
      "source": [
        "segmentation_id = 1\n",
        "for annotation_filename in Tqdm(annotation_files):\n",
        "    image_id = [f for f in coco_output['images'] if stem(f['file_name'])==annotation_filename.split('_')[0]][0]['id']\n",
        "    class_id = [x['id'] for x in CATEGORIES if x['name'] in annotation_filename][0]\n",
        "    category_info = {'id': class_id, 'is_crowd': 'crowd' in image_filename}\n",
        "    binary_mask = np.asarray(Image.open(f'{ANNOTATION_DIR}/{annotation_filename}').convert('1')).astype(np.uint8)\n",
        "\n",
        "    annotation_info = pycococreatortools.create_annotation_info(segmentation_id, image_id, category_info, binary_mask, image.size, tolerance=2)\n",
        "\n",
        "    if annotation_info is not None:\n",
        "        coco_output[\"annotations\"].append(annotation_info)\n",
        "        segmentation_id = segmentation_id + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QshA9U_lyPlv"
      },
      "outputs": [],
      "source": [
        "coco_output['categories'] = [{'id': id+1, 'name': clss_name, 'supercategory': 'none'} for id,(_,(name, clss_name)) in enumerate(classes.iterrows())]\n",
        "\n",
        "import json\n",
        "with open('images.json', 'w') as output_json_file:\n",
        "    json.dump(coco_output, output_json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgKDlPCeyRCP"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "# install detectron2:\n",
        "!git clone https://github.com/facebookresearch/detectron2\n",
        "%cd /content/detectron2\n",
        "%pip install -r requirements.txt\n",
        "!python setup.py install\n",
        "%cd /content\n",
        "!git clone https://github.com/facebookresearch/fvcore.git\n",
        "%cd /content/fvcore\n",
        "%pip install -e .\n",
        "%cd /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvBt1S_xLSaq"
      },
      "outputs": [],
      "source": [
        "from torch_snippets import *\n",
        "required_classes = 'person,dog,bird,car,elephant,football,jug,laptop,mushroom,pizza,rocket,shirt,traffic sign,watermelon,zebra'\n",
        "required_classes = [c.lower() for c in required_classes.lower().split(',')]\n",
        "\n",
        "classes = pd.read_csv('classes.csv', header=None)\n",
        "classes.columns = ['class','class_name']\n",
        "classes = classes[classes['class_name'].map(lambda x: x in required_classes)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42_JaPvtUg-R"
      },
      "source": [
        "restart the notebook if below cell fails to execute,  \n",
        "and start running from above cell  \n",
        "no need to run from the very top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgowdCn3ytx5"
      },
      "outputs": [],
      "source": [
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.engine import DefaultTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72_l7xUW81pR"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"dataset_train\", {}, \"images.json\", \"train/myData2020\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri6QC_Oi84WV"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"dataset_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\") # pretrained weights\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025 # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 5000 # instead of epochs, we train on 5000 batches\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYe7DxIH86Fh"
      },
      "outputs": [],
      "source": [
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8Rj9SObGi8z"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
        "predictor = DefaultPredictor(cfg)\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "files = Glob('train/myData2020')\n",
        "for _ in range(30):\n",
        "    im = cv2.imread(str(choose(files)))\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                    scale=0.5,\n",
        "                    metadata=MetadataCatalog.get(\"dataset_train\"),\n",
        "                    instance_mode=ColorMode.IMAGE_BW\n",
        "    # remove the colors of unsegmented pixels.\n",
        "    # This option is only available for segmentation models\n",
        "    )\n",
        "\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    show(out.get_image())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJNdsxuVLI9D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}